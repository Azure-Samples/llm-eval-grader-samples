# Contoso LLM Chatbot

This is a sample chatbot for Contoso. It is built using Azure Open AI and Streamlit.
This application is used to populate the data for user and chatbot interaction, that is used to demonstrate the LLM Based Evaluation.

## Prerequisites

The following are the prerequisites to run this app:

- Azure Subscription: To run this app, you need an Azure subscription.
- Azure OpenAI Resource: You need to have an Azure OpenAI resource to run this app.
- GPT3.5 Model in Azure OpenAI: You need to have GPT3.5 model deployed in Azure OpenAI resource.
- Azure Application Insights: You need to have an Azure Application Insights resource to store the data.

## Installation

This app can be run from anywhere using `Python` and `streamlit` command.

Before running the `.env` file should be created in this directory by copying the `.env_template` file and updating the values in the `.env` file.

```bash
API_KEY=<your azure openai api key>
AZURE_ENDPOINT=<your azure openai api endpoint>
API_VERSION=2024-02-01
DEPLOYMENT_NAME=<your azure openai model deployment name>
APPLICATIONINSIGHTS_CONNECTION_STRING="<your application insights connection string>"
```

To run his app, execute the following command:

```bash
# Install the required libraries
pip install -r requirements.txt
# Run the app
streamlit run app.py
```

This will open a new tab in your default browser with the chatbot interface. For detailed instruction on how to run streamlit app, please refer to the [Streamlit Documentation](https://docs.streamlit.io/develop/concepts/architecture/run-your-app).

## Usage

This app can create conversation with more than one turn. The following are the steps to create a conversation:

1. Enter the user query in the text box called `Enter a query:`. Ex. "Please suggest me a good TV."
1. Click on the `Generate Response` button to send the query to the chatbot.
1. The chatbot will respond with the answer to the query.
1. The conversation can be continued by entering the next query in the text box and clicking on the `Generate Response` button. Ex. "Size 55 inch."
1. A new conversation can be started by clicking on the `New Conversation` button.

## How this app works

This main purpose of this app is to populate data that can be evaluated. While the user interacts with the chatbot, the following things happen:

1. The user query is sent to the OpenAI GPT-3.5 model to detect intent of the query. The intent can be any of the following: "grocery", "home", "clothing", "electronics", "pharmacy", "general"
1. Based on the intent, the chatbot will call the respective Prompt and make another call to the OpenAI GPT-3.5 model to generate the response. Basically there will be two calls to the OpenAI GPT-3.5 model for each user query.
1. The response generated by the OpenAI GPT-3.5 model is displayed in the chatbot interface.
1. The chatbot will also display the previous conversation in the chatbot interface for a given conversation.
1. When user clicks on the `New Conversation` button, the chatbot will clear the conversation history and start a new conversation.
1. Data logging: The following data is logged for each conversation at different stages:
    1. Conversation Data: For each query the following data is logged:
        1. User Query: The query entered by the user.
        1. Chatbot Response: The response that user gets from the chatbot.
        1. Conversation ID: The ID of the conversation.
        1. Turn ID: The ID of the turn in the conversation.
    1. LLM Data: For each OpenAI GPT-3.5 model call the following data is logged:
        1. User Query: The query entered by the user.
        1. Intent: The intent detected by the OpenAI GPT-3.5 model.
        1. LLM Response: The response generated by the OpenAI GPT-3.5 model.
        1. Conversation ID: The ID of the conversation.
        1. Turn ID: The ID of the turn in the conversation.
        1. Model: The name of the model used for the call, ex. grocery-model, home-model, etc.

## Data Storage

The data is store in Azure Application Insights. The data is stored in table `traces` in the Application Insights. 

## Populate Larger Set of Data

Though this app can be used to populate data by entering queries manually, it can also be used to populate data by running the app in a loop for a given set of queries in [questions.csv](./questions.csv) file. To run the app in a loop, execute the following command:

```bash
python populate_data.py
```

This will populate data for 824 turns that is part of 330 conversations. This will also populate LLM data for 1648 Azure OpenAI GPT-3.5 model calls. The data will be stored in the Azure Application Insights.

**Note:** This step will take some time to populate the data and also it will make 1648 calls to the Azure OpenAI GPT-3.5 model. Make sure you have enough credits in your OpenAI account to make these calls.

## How to develop this app further

This app can be further developed by adding more intents and prompts to the app or by extending streamlit app to add more features. The [Streamlit Documentation](https://docs.streamlit.io/develop/concepts/design) can be referred to add more features to the app.
